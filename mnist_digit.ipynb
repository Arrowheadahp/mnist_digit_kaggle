{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, \n",
    "                                     Dropout, \n",
    "                                     Activation, \n",
    "                                     Flatten, \n",
    "                                     Conv2D, \n",
    "                                     MaxPooling2D, \n",
    "                                     Reshape, \n",
    "                                     Lambda,\n",
    "                                     Input\n",
    "                                    )\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_train = 'data\\\\train.csv'\n",
    "loc_test = 'data\\\\test.csv'\n",
    "target = 'label'\n",
    "\n",
    "raw_train_data = pd.read_csv(loc_train)\n",
    "y = raw_train_data[target]\n",
    "raw_test_data = pd.read_csv(loc_test)\n",
    "# raw_train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(raw_DF):\n",
    "    DF = raw_DF.copy()\n",
    "    if target in DF.columns:\n",
    "        DF = DF.drop(columns = [target], axis = 1)\n",
    "\n",
    "    DF = DF.values.reshape(-1, 28, 28, 1)\n",
    "    DF = DF/255  \n",
    "\n",
    "#     DF = (DF-mean_px)/std_px\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare(raw_train_data)\n",
    "X_test = prepare(raw_test_data)\n",
    "\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x): \n",
    "    return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Val_x, y, val_y = train_test_split(X_train, y, random_state = 249, test_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0][:, :, 0], \n",
    "          cmap = plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = [\n",
    "    Input(shape=(784,)), \n",
    "    Lambda(lambda x: x/255.0), \n",
    "    Reshape((28, 28, 1))\n",
    "]\n",
    "\n",
    "CNN = [\n",
    "    Conv2D(32, \n",
    "           (5, 5), \n",
    "           activation='relu' \n",
    "          ), \n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.07,\n",
    "    height_shift_range=0.07,\n",
    "    brightness_range=None, \n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    channel_shift_range=0.1,\n",
    "    horizontal_flip=False, \n",
    "    vertical_flip=False,     \n",
    "    \n",
    "    validation_split = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://keras.io/api/callbacks/\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "                    filepath='models', \n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=False\n",
    "                   ), \n",
    "    EarlyStopping(patience = 4,\n",
    "                  restore_best_weights=True,\n",
    "                  monitor = 'val_loss'\n",
    "    ),\n",
    "#     TensorBoard(),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# model.add(Lambda(standardize, input_shape=(28,28,1)))\n",
    "\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#         Lambda(standardize, input_shape=(28,28,1)),\n",
    "#         Conv2D(32,(3,3), activation='relu'),\n",
    "#         BatchNormalization(axis=1),\n",
    "#         Conv2D(32,(3,3), activation='relu'),\n",
    "#         MaxPooling2D(),\n",
    "#         BatchNormalization(axis=1),\n",
    "#         Conv2D(64,(3,3), activation='relu'),\n",
    "#         BatchNormalization(axis=1),\n",
    "#         Conv2D(64,(3,3), activation='relu'),\n",
    "#         MaxPooling2D(),\n",
    "#         Flatten(),\n",
    "#         BatchNormalization(),\n",
    "#         Dense(512, activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "#         Dense(10, activation='softmax')\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',  \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics= ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1000 steps, validate on 10000 samples\n",
      "Epoch 1/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3083 - accuracy: 0.9057WARNING:tensorflow:From C:\\Users\\prasu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models\\assets\n",
      "1000/1000 [==============================] - 525s 525ms/step - loss: 0.3083 - accuracy: 0.9057 - val_loss: 0.1068 - val_accuracy: 0.9714\n",
      "Epoch 2/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9625INFO:tensorflow:Assets written to: models\\assets\n",
      "1000/1000 [==============================] - 524s 524ms/step - loss: 0.1276 - accuracy: 0.9625 - val_loss: 0.0564 - val_accuracy: 0.9863\n",
      "Epoch 3/32\n",
      "1000/1000 [==============================] - 513s 513ms/step - loss: 0.1033 - accuracy: 0.9709 - val_loss: 0.0749 - val_accuracy: 0.9838\n",
      "Epoch 4/32\n",
      "1000/1000 [==============================] - 512s 512ms/step - loss: 0.0875 - accuracy: 0.9756 - val_loss: 0.0645 - val_accuracy: 0.9862\n",
      "Epoch 5/32\n",
      "1000/1000 [==============================] - 513s 513ms/step - loss: 0.0813 - accuracy: 0.9783 - val_loss: 0.0673 - val_accuracy: 0.9865\n",
      "Epoch 6/32\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9797INFO:tensorflow:Assets written to: models\\assets\n",
      "1000/1000 [==============================] - 518s 518ms/step - loss: 0.0740 - accuracy: 0.9797 - val_loss: 0.0472 - val_accuracy: 0.9908\n",
      "Epoch 7/32\n",
      "1000/1000 [==============================] - 520s 520ms/step - loss: 0.0726 - accuracy: 0.9808 - val_loss: 0.0523 - val_accuracy: 0.9911\n",
      "Epoch 8/32\n",
      "1000/1000 [==============================] - 515s 515ms/step - loss: 0.0709 - accuracy: 0.9819 - val_loss: 0.0492 - val_accuracy: 0.9907\n",
      "Epoch 9/32\n",
      "1000/1000 [==============================] - 516s 516ms/step - loss: 0.0689 - accuracy: 0.9825 - val_loss: 0.0703 - val_accuracy: 0.9870\n",
      "Epoch 10/32\n",
      "1000/1000 [==============================] - 515s 515ms/step - loss: 0.0573 - accuracy: 0.9845 - val_loss: 0.0590 - val_accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    datagen.flow(X_train, y), \n",
    "    epochs = 32,\n",
    "#     validation_split = 0.25,\n",
    "    validation_data = (Val_x, val_y),\n",
    "#     verbose = 2\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 29s 3ms/sample - loss: 0.0472 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.047220742002183035, 0.9908]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev = model.evaluate(Val_x, val_y)\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ImageId': range(1, len(X_test)+1), 'Label': predictions})\n",
    "output.to_csv('preds\\\\bn_c9c5pc5c3_512_10_e-es16.csv', index = False)\n",
    "# output.to_csv('bnn_sparse.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = keras.models.load_model('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(sm.predict(Val_x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9908"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p==val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 29s 3ms/sample - loss: 0.0456 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04561601200666264, 0.9908]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.evaluate(Val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitb122d7ed60ea485982511a1bcddbd83a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
